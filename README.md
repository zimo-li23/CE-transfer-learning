# CE-transfer-learning
We propose a deep learning framework that combines transfer learning with cluster expansion method for accurately predicting the physical properties of high-entropy alloys. The cluster expansion method establishes a physical model of the alloy system using the original data, while the transfer learning model extracts important physical information from the data generated by cluster expansion for prediction. When applied to the FeNiCoCrMn/Pd high-entropy alloy systems, the framework shows significant enhancement in the prediction accuracy of formation energy and atomic magnetic moment. The transfer learning model maintains good prediction performance even at the small dataset limit. The proposed framework combines the efficient data utilization of transfer learning with the clear physical insights of cluster expansion, augmenting the predictive capability of machine learning on small datasets.

**Documents:** 

The folder HEA_data contains all the HEA data used to train the model.

structure_stat.py is used to statistically analyze structural information to obtain atomic occupantion probabilities. 

generate.py is used to generate new samples by cluster expansion.

main.py is used to train Scratch and Scratch′ models.

main_transfer.py is used to train DA and TL models.

common.py contains the network structures of machine learning models and defines the generic functions.

**Environment Requirements:**
The basic environment is PyTorch, and CUDA for GPU machines.

**Workflow:**

First use structure_stat.py to statistically analyze structural information from the POSCARs. This file can be run directly. The obtained occupantion probabilities for FCC and BCC are stored separately in fcc_train.csv and bcc_train.csv.

Use main.py to train Scratch and Scratch′ models. This file can be run directly.

Reference values for the accuracy of Scratch models: 

Train: R2: 0.9576119015725071, loss: 0.042388

Test: R2: 0.910952639191531, loss: 0.051504

Use main_transfer.py to train DA and TL models. This file can be run directly.

Reference values for the accuracy of TL models:

Train: R2: 0.9501818692776184, loss: 0.049818

Test: R2: 0.9466268808883479, loss: 0.030870
